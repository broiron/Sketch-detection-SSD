{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe0665ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/broiron/.local/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from utils.augmentations import SSDAugmentation\n",
    "from layers.modules import MultiBoxLoss\n",
    "from ssd import build_ssd\n",
    "import os\n",
    "import sys \n",
    "import time\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.init as init\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ca61ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "    \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5a51d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sys.version_info[0] == 2:\n",
    "    import xml.etree.cElementTree as ET\n",
    "else:\n",
    "    import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cce24940",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOC_CLASSES = ('line', 'background')\n",
    "\n",
    "class VOCAnnotationTransform(object):\n",
    "    \n",
    "    def __init__(self, class_to_ind=None, keep_difficult=False):\n",
    "        \n",
    "        '''\n",
    "        self.class_to_ind = class_to_ind or dict(\n",
    "            zip(VOC_CLASSES, range(len(VOC_CLASSES))))\n",
    "        '''\n",
    "        self.class_to_ind = {'line' : 0, 'background' : 1}\n",
    "        self.keep_difficult = keep_difficult\n",
    "    def __call__(self, target, width, height):\n",
    "        \n",
    "        res = []\n",
    "        for obj in target.iter('object'):\n",
    "            difficult = int(obj.find('difficult').text) == 1\n",
    "            if not self.keep_difficult and difficult:\n",
    "                continue\n",
    "            name = obj.find('name').text.lower().strip()\n",
    "            bbox = obj.find('bndbox')\n",
    "\n",
    "            pts = ['xmin', 'ymin', 'xmax', 'ymax']\n",
    "            bndbox = []\n",
    "            for i, pt in enumerate(pts):\n",
    "                cur_pt = int(float(bbox.find(pt).text)) - 1\n",
    "                # scale height or width\n",
    "                cur_pt = cur_pt / width if i % 2 == 0 else cur_pt / height\n",
    "                bndbox.append(cur_pt)\n",
    "            label_idx = self.class_to_ind[name]\n",
    "            bndbox.append(label_idx)\n",
    "            res += [bndbox]  # [xmin, ymin, xmax, ymax, label_ind]\n",
    "            # img_id = target.find('filename').text[:-4]\n",
    "\n",
    "        return res  # [[xmin, ymin, xmax, ymax, label_ind], ... ]\n",
    "\n",
    "class VOCDetection(data.Dataset):\n",
    "    def __init__(self, root, transform=None, \n",
    "                 target_transform=VOCAnnotationTransform(), \n",
    "                 dataset_name='line_dataset1'):\n",
    "        \n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.name = dataset_name\n",
    "        self._annopath = os.path.join('%s', 'Annotations', '%s.xml')\n",
    "        self._imgpath = os.path.join('%s', 'JPEGImages', '%s.jpg')\n",
    "        \n",
    "        self.ids = list()\n",
    "        for line in open(os.path.join(self.root, 'ImageSets', 'Main', 'default.txt')):\n",
    "            self.ids.append((self.root, line.strip()))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        im, gt, h, w = self.pull_item(index)\n",
    "        #im, boxes, labels, h, w = self.pull_item(index)\n",
    "        return im, gt\n",
    "        #return im, boxes, labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "    \n",
    "    def pull_item(self, index):\n",
    "        img_id = self.ids[index]\n",
    "        \n",
    "        target = ET.parse(self._annopath % img_id).getroot()\n",
    "        img = cv2.imread(self._imgpath % img_id)\n",
    "        height, width, channels = img.shape\n",
    "        \n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target, width, height)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            target = np.array(target)\n",
    "            img, boxes, labels = self.transform(img, target[:, :4], target[:, 4])\n",
    "            # img, boxes, labels = self.transform(img, target[:4], target[4])\n",
    "            # to rgb\n",
    "            img = img[:, :, (2, 1, 0)]\n",
    "            # img = img.transpose(2, 0, 1)\n",
    "            boxes[:, 2] = boxes[:, 0] + boxes[:, 2]\n",
    "            boxes[:, 3] = boxes[:, 1] + boxes[:, 3]\n",
    "            target = np.hstack((boxes, np.expand_dims(labels, axis=1)))\n",
    "        return torch.from_numpy(img).permute(2, 0, 1), target, height, width\n",
    "    \n",
    "    def pull_image(self, index):\n",
    "        # Return the original image object at index in PIL form\n",
    "        img_id = self.ids[index]\n",
    "        return cv2.imread(self._imgpath % img_id, cv2.IMREAD_COLOR)\n",
    "    \n",
    "    def pull_anno(self, index):\n",
    "        # Returns the original annotation of image at index\n",
    "        img_id = self.ids[index]\n",
    "        anno = ET.parse(self._annopath % img_id).getroot()\n",
    "        gt = self.target_transform(anno, 1, 1)\n",
    "        return img_id[1], gt\n",
    "\n",
    "    def pull_tensor(self, index):\n",
    "        # Returns the original image at an index in tensor form\n",
    "        return torch.Tensor(self.pull_image(index)).unsqueeze_(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ef598b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = VOCDetection(root='/home/broiron/broiron/model_train/ssd-pytorch-custom/line_dataset2/',\n",
    "                        transform=SSDAugmentation(size=300, mean=(104, 117, 123)),\n",
    "                       target_transform=VOCAnnotationTransform()\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001b9480",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd13bd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/home/broiron/broiron/model_train/ssd_pytorch/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bd73310",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssd_net = build_ssd('train', 300, num_classes=2)\n",
    "net = ssd_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e33cd7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading base network...\n"
     ]
    }
   ],
   "source": [
    "vgg_weights = torch.load(os.path.join(base_dir, 'weights/vgg16_reducedfc.pth'))\n",
    "print(\"loading base network...\")\n",
    "ssd_net.vgg.load_state_dict(vgg_weights)\n",
    "\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4c7d074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting with default value\n",
    "optimizer = optim.SGD(net.parameters(), lr=1e-3, momentum=0.9,\n",
    "                          weight_decay=5e-4) \n",
    "'''\n",
    "criterion = MultiBoxLoss(num_classes=2, overlap_thresh=0.5, prior_for_matching=True, \n",
    "                         bkg_label=1, neg_mining=True, neg_pos=3, neg_overlap=0.5, \n",
    "                         encode_target=False, use_gpu=True)\n",
    "'''\n",
    "\n",
    "criterion = MultiBoxLoss(2, 0.5, True, 0, True, 3, 0.5, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d948d395",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection_collate(batch):\n",
    "    \"\"\"Custom collate fn for dealing with batches of images that have a different\n",
    "    number of associated object annotations (bounding boxes).\n",
    "    Arguments:\n",
    "        batch: (tuple) A tuple of tensor images and lists of annotations\n",
    "    Return:\n",
    "        A tuple containing:\n",
    "            1) (tensor) batch of images stacked on their 0 dim\n",
    "            2) (list of tensors) annotations for a given image are stacked on 0 dim\n",
    "    \"\"\"\n",
    "    targets = []\n",
    "    imgs = []\n",
    "    for sample in batch:\n",
    "        imgs.append(sample[0])\n",
    "        targets.append(torch.FloatTensor(sample[1]))\n",
    "    return torch.stack(imgs, 0), targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d14674f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset...\n",
      "Training SSD on:  line_dataset1\n",
      "Data loader length... 8\n"
     ]
    }
   ],
   "source": [
    "net.train()\n",
    "\n",
    "loc_loss = 0\n",
    "conf_loss = 0\n",
    "epoch = 0\n",
    "batch_size = 32\n",
    "\n",
    "print('loading dataset...')\n",
    "\n",
    "epoch_size = len(dataset) // batch_size\n",
    "\n",
    "print('Training SSD on: ', dataset.name)\n",
    "\n",
    "step_index = 0\n",
    "\n",
    "data_loader = data.DataLoader(dataset, batch_size, num_workers=4, shuffle=False, collate_fn=detection_collate,\n",
    "                             pin_memory=True)\n",
    "print('Data loader length...', len(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca00a1ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/broiron/broiron/model_train/ssd-pytorch-custom/utils/augmentations.py:238: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  mode = random.choice(self.sample_options)\n",
      "/home/broiron/broiron/model_train/ssd-pytorch-custom/utils/augmentations.py:238: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  mode = random.choice(self.sample_options)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Caught IndexError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/broiron/anaconda3/envs/ssd_train/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 198, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/broiron/anaconda3/envs/ssd_train/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/broiron/anaconda3/envs/ssd_train/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/tmp/ipykernel_56242/1694714558.py\", line 55, in __getitem__\n    im, boxes, labels, h, w = self.pull_item(index)\n  File \"/tmp/ipykernel_56242/1694714558.py\", line 75, in pull_item\n    img, boxes, labels = self.transform(img, target[:4], target[4])\nIndexError: index 4 is out of bounds for axis 0 with size 1\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_56242/430632652.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ssd_train/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ssd_train/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1083\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ssd_train/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1111\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1112\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ssd_train/lib/python3.7/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0;31m# have message field\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Caught IndexError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/broiron/anaconda3/envs/ssd_train/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 198, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/broiron/anaconda3/envs/ssd_train/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/broiron/anaconda3/envs/ssd_train/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/tmp/ipykernel_56242/1694714558.py\", line 55, in __getitem__\n    im, boxes, labels, h, w = self.pull_item(index)\n  File \"/tmp/ipykernel_56242/1694714558.py\", line 75, in pull_item\n    img, boxes, labels = self.transform(img, target[:4], target[4])\nIndexError: index 4 is out of bounds for axis 0 with size 1\n"
     ]
    }
   ],
   "source": [
    "batch_iterator = iter(data_loader)\n",
    "for iteration in range(0, 120000):\n",
    "    loc_loss = 0\n",
    "    conf_loss = 0\n",
    "    epoch += 1\n",
    "    \n",
    "    \n",
    "    images, targets= next(batch_iterator)\n",
    "    with torch.no_grad():\n",
    "        images = Variable(images.to(device))\n",
    "        targets = [Variable(ann.to(device)) for ann in targets]\n",
    "    \n",
    "    # forward\n",
    "    t0 = time.time()\n",
    "    out = net(images)\n",
    "    \n",
    "    # backward\n",
    "    optimizer.zero_grad()\n",
    "    loss_l, loss_c = criterion(out, targets)\n",
    "    loss = loss_l + loss_c\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    t1 = time.time()\n",
    "\n",
    "    loc_loss += loss_l.data.item()\n",
    "    conf_loss += loss_c.data.item()\n",
    "    \n",
    "    if iteration % 1 == 0:\n",
    "        print('timer: %.4f sec.' % (t1 - t0))\n",
    "        print('iter ' + repr(iteration) + ' || Loss: %.4f ||' % (loss.data.item()), end=' ')\n",
    "    \n",
    "    if iteration != 0 and iteration % 5000 == 0:\n",
    "        print('Saving state, iter:', iteration)\n",
    "        torch.save(ssd_net.state_dict(), 'weights/ssd300_line_' +\n",
    "                       repr(iteration) + '.pth')\n",
    "torch.save(ssd_net.state_dict(), './weights/linedataset1'+ '.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7313de3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epoch = 100\n",
    "for epoch in range(0, epoch):\n",
    "    for batch, data in enumerate(data_loader, 1):\n",
    "        loc_loss = 0\n",
    "        conf_loss = 0\n",
    "        epoch += 1\n",
    "        \n",
    "        images, targets = data[0], data[1]\n",
    "        \n",
    "        '''\n",
    "        with torch.no_grad():\n",
    "        images = Variable(images.to(device))\n",
    "        targets = [Variable(ann.to(device)) for ann in targets]\n",
    "        '''\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c77f6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fb792e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38197a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc9e4d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssd_train",
   "language": "python",
   "name": "ssd_train"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
