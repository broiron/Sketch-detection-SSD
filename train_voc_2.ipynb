{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0b42ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/broiron/.local/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from data import *\n",
    "from data.config import custom\n",
    "from utils.augmentations import SSDAugmentation\n",
    "from layers.modules import MultiBoxLoss\n",
    "from ssd import build_ssd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.init as init\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d73f830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "    \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad007957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/broiron/broiron/line_dataset_vol2_pascal_test\n"
     ]
    }
   ],
   "source": [
    "print(VOC_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b52880c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_root = '/home/broiron/broiron/line_dataset_vol3_pascal/'\n",
    "cfg = voc\n",
    "\n",
    "dataset = VOCDetection(root=dataset_root, transform=SSDAugmentation(cfg['min_dim'],\n",
    "                                                    MEANS), image_sets='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b22c0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = VOCDetection(root=dataset_root, transform=SSDAugmentation(cfg['min_dim'],\n",
    "                                                    MEANS), image_sets='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88797d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading base network...\n"
     ]
    }
   ],
   "source": [
    "base_dir = '/home/broiron/broiron/model_train/ssd_pytorch/'\n",
    "\n",
    "ssd_net = build_ssd('train', 300, num_classes=2)\n",
    "net = ssd_net\n",
    "\n",
    "vgg_weights = torch.load(os.path.join(base_dir, 'weights/vgg16_reducedfc.pth'))\n",
    "print(\"loading base network...\")\n",
    "ssd_net.vgg.load_state_dict(vgg_weights)\n",
    "\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24cfc25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "597\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))\n",
    "print(len(testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "788fcadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting with default value\n",
    "optimizer = optim.SGD(net.parameters(), lr=1e-5, momentum=0.9, # 1e-3 -> 1e-5\n",
    "                          weight_decay=5e-4) \n",
    "'''\n",
    "criterion = MultiBoxLoss(num_classes=2, overlap_thresh=0.\n",
    "5, prior_for_matching=True, \n",
    "                         bkg_label=1, neg_mining=True, neg_pos=3, neg_overlap=0.5, \n",
    "                         encode_target=False, use_gpu=True)\n",
    "'''\n",
    "\n",
    "criterion = MultiBoxLoss(2, 0.5, True, 0, True, 3, 0.5, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ce88c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection_collate(batch):\n",
    "    \"\"\"Custom collate fn for dealing with batches of images that have a different\n",
    "    number of associated object annotations (bounding boxes).\n",
    "    Arguments:\n",
    "        batch: (tuple) A tuple of tensor images and lists of annotations\n",
    "    Return:\n",
    "        A tuple containing:\n",
    "            1) (tensor) batch of images stacked on their 0 dim\n",
    "            2) (list of tensors) annotations for a given image are stacked on 0 dim\n",
    "    \"\"\"\n",
    "    targets = []\n",
    "    imgs = []\n",
    "    for sample in batch:\n",
    "        imgs.append(sample[0])\n",
    "        targets.append(torch.FloatTensor(sample[1]))\n",
    "    return torch.stack(imgs, 0), targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f430e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset...\n",
      "Training SSD on:  default\n",
      "Data loader length... 19\n"
     ]
    }
   ],
   "source": [
    "net.train()\n",
    "\n",
    "loc_loss = 0\n",
    "conf_loss = 0\n",
    "epoch = 0\n",
    "batch_size = 32\n",
    "\n",
    "print('loading dataset...')\n",
    "\n",
    "epoch_size = len(dataset) // batch_size\n",
    "\n",
    "print('Training SSD on: ', dataset.name)\n",
    "\n",
    "step_index = 0\n",
    "\n",
    "data_loader = data.DataLoader(dataset, batch_size, num_workers=4, shuffle=False, collate_fn=detection_collate,\n",
    "                             pin_memory=True)\n",
    "print('Data loader length...', len(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2e59e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3420\n"
     ]
    }
   ],
   "source": [
    "iter_size = len(data_loader) * epoch_size * 10\n",
    "print(iter_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a61ef4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/broiron/broiron/model_train/ssd-pytorch-custom/utils/augmentations.py:238: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  mode = random.choice(self.sample_options)\n",
      "/home/broiron/broiron/model_train/ssd-pytorch-custom/utils/augmentations.py:238: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  mode = random.choice(self.sample_options)\n",
      "/home/broiron/broiron/model_train/ssd-pytorch-custom/utils/augmentations.py:238: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  mode = random.choice(self.sample_options)\n",
      "/home/broiron/broiron/model_train/ssd-pytorch-custom/utils/augmentations.py:238: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  mode = random.choice(self.sample_options)\n",
      "/home/broiron/anaconda3/envs/ssd_train/lib/python3.7/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timer: 0.7175 sec.\n",
      "iter 0 || Loss: 134.4066 || timer: 0.2653 sec.\n",
      "iter 1 || Loss: 111.1611 || timer: 0.2728 sec.\n",
      "iter 2 || Loss: 87.0140 || timer: 0.2626 sec.\n",
      "iter 3 || Loss: 74.9819 || "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18392/2657152026.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mloc_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mconf_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "\n",
    "batch_iterator = iter(data_loader)\n",
    "for iteration in range(0, iter_size):\n",
    "    loc_loss = 0\n",
    "    conf_loss = 0\n",
    "    epoch += 1\n",
    "    \n",
    "    try:\n",
    "        images, targets = next(batch_iterator)\n",
    "    except StopIteration:\n",
    "        batch_iterator = iter(data_loader)\n",
    "        images, targets = next(batch_iterator)\n",
    "    \n",
    "    # images, targets= next(batch_iterator)\n",
    "    with torch.no_grad():\n",
    "        images = Variable(images.to(device))\n",
    "        targets = [Variable(ann.to(device)) for ann in targets]\n",
    "    \n",
    "    # forward\n",
    "    t0 = time.time()\n",
    "    out = net(images)\n",
    "    \n",
    "    # backward\n",
    "    optimizer.zero_grad()\n",
    "    loss_l, loss_c = criterion(out, targets)\n",
    "    loss = loss_l + loss_c\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    t1 = time.time()\n",
    "\n",
    "    loc_loss += loss_l.data.item()\n",
    "    conf_loss += loss_c.data.item()\n",
    "    \n",
    "    if iteration % 1 == 0:\n",
    "        print('timer: %.4f sec.' % (t1 - t0))\n",
    "        print('iter ' + repr(iteration) + ' || Loss: %.4f ||' % (loss.data.item()), end=' ')\n",
    "        losses.append(loss.data.item())\n",
    "    \n",
    "    if iteration != 0 and iteration % 500 == 0:\n",
    "        print('Saving state, iter:', iteration)\n",
    "        torch.save(ssd_net.state_dict(), 'weights/ssd300_line2_' +\n",
    "                       repr(iteration) + '.pth')\n",
    "torch.save(ssd_net.state_dict(), './weights/linedataset_ver2_1a'+ '.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a26e3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssd_train",
   "language": "python",
   "name": "ssd_train"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
