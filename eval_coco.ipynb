{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1eea232a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/broiron/.local/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from utils.augmentations import SSDAugmentation\n",
    "from layers.modules import MultiBoxLoss\n",
    "from ssd import build_ssd\n",
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from data import *\n",
    "from PIL import Image\n",
    "from utils.augmentations import SSDAugmentation\n",
    "from layers.functions import Detect\n",
    "from data import COCO_CLASSES, COCOAnnotationTransform\n",
    "\n",
    "import torch.utils.data as data\n",
    "from ssd import build_ssd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e563a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "    \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "save_folder = os.path.join(os.getcwd(), 'test')\n",
    "if not os.path.exists(save_folder):\n",
    "    os.mkdir(save_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93d30d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_net(save_folder, net, cuda, testset, transform, thresh):\n",
    "    # dump predictions and assoc. ground truth to text file for now\n",
    "    \n",
    "    detect = Detect(num_classes=2, bkg_label=1, top_k=200, conf_thresh=0.01, nms_thresh=0.445)\n",
    "    \n",
    "    filename = os.path.join(save_folder, 'test1.txt')\n",
    "    num_images = len(testset)\n",
    "    for i in range(num_images):\n",
    "        print('Testing image {:d}/{:d}....'.format(i+1, num_images))\n",
    "        img, annotation, h, w, img_id = testset.pull_item(i)\n",
    "        print(img_id)\n",
    "        annotation = testset.pull_anno(i)\n",
    "\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        with torch.no_grad():\n",
    "            x = img.unsqueeze(0)\n",
    "            x = x.type(torch.FloatTensor)\n",
    "            x = x.to(device)\n",
    "            x = Variable(x)\n",
    "\n",
    "            with open(filename, mode='a') as f:\n",
    "                f.write('\\nGROUND TRUTH FOR: '+str(img_id)+'\\n')\n",
    "                #for box in annotation: \n",
    "                #    f.write('label: '+' || '.join(str(b) for b in box)+'\\n')\n",
    "                for box in annotation:\n",
    "                    f.write('label: '+' || '.join(str(b) for b in box['bbox']) + '|| ' + str(box['category_id'])+'\\n')\n",
    "\n",
    "            net = net.to(device)\n",
    "\n",
    "            #y = net(x) # forward pass\n",
    "            y = net.forward(x)\n",
    "            y = detect.forward(y[0], y[1], y[2])\n",
    "        detections = y.data    \n",
    "        # scale each detection back up to the image\n",
    "        #scale = torch.Tensor([img.shape[1], img.shape[0],\n",
    "        #                    img.shape[1], img.shape[0]])\n",
    "        scale = torch.Tensor([w, h, w, h])\n",
    "        \n",
    "        pred_num = 0\n",
    "        for i in range(detections.size(1)):\n",
    "            j = 0\n",
    "            while detections[0, i, j, 0] >= 0.6:\n",
    "                if pred_num == 0:\n",
    "                    with open(filename, mode='a') as f:\n",
    "                        f.write('PREDICTIONS: '+'\\n')\n",
    "                score = detections[0, i, j, 0]\n",
    "                # label_name = CUSTOM_CLASSES[i-1]\n",
    "                label_name = COCO_CLASSES[i-1]\n",
    "                pt = (detections[0, i, j, 1:]*scale).cpu().numpy()\n",
    "                coords = (pt[0], pt[1], pt[2], pt[3])\n",
    "                pred_num += 1\n",
    "                with open(filename, mode='a') as f:\n",
    "                    f.write(str(pred_num)+' label: '+label_name+' score: ' +\n",
    "                            str(score) + ' '+' || '.join(str(c) for c in coords) + '\\n')\n",
    "                print(str(pred_num)+' label: '+label_name+' score: ' +\n",
    "                            str(score) + ' '+' || '.join(str(c) for c in coords))\n",
    "                j += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "081f28d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f803b9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "dataset = COCODetection(root='/home/broiron/broiron/line_dataset_vol1_coco/', \n",
    "                        transform=SSDAugmentation(300, MEANS), image_set='test',\n",
    "                       target_transform=COCOAnnotationTransform())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e422aedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/broiron/broiron/model_train/ssd-pytorch-custom/utils/augmentations.py:238: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  mode = random.choice(self.sample_options)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8006/3134291762.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpull_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "img, annotation, h, w= dataset.pull_item(10)\n",
    "\n",
    "img.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d63e3367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 938.25 || 316.61 || 977.87 || 971.6800000000001|| 1\n",
      "\n",
      "label: 434.62 || 425.95 || 1005.61 || 458.15|| 1\n",
      "\n",
      "label: 684.76 || 889.08 || 1254.51 || 926.23|| 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "anno = dataset.pull_anno(10)\n",
    "for box in anno:\n",
    "    print('label: '+' || '.join(str(b) for b in box['bbox']) + '|| ' + str(box['category_id'])+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4643b58b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------anno1----------\n",
      "[[0.         0.         0.40837796 0.85610996 0.        ]\n",
      " [0.02430757 0.         0.79371079 0.43682573 0.        ]\n",
      " [0.         0.4419917  0.60232594 1.         0.        ]]\n",
      "--------anno2----------\n",
      "[{'area': 25953.8734, 'attributes': {'occluded': False, 'rotation': 0.0}, 'bbox': [938.25, 316.61, 1916.12, 1288.29], 'category_id': 1, 'id': 169, 'image_id': 58, 'iscrowd': 0, 'segmentation': []}, {'area': 18385.877999999993, 'attributes': {'occluded': False, 'rotation': 0.0}, 'bbox': [434.62, 425.95, 1440.23, 884.0999999999999], 'category_id': 1, 'id': 170, 'image_id': 58, 'iscrowd': 0, 'segmentation': []}, {'area': 21166.212499999987, 'attributes': {'occluded': False, 'rotation': 0.0}, 'bbox': [684.76, 889.08, 1939.27, 1815.31], 'category_id': 1, 'id': 171, 'image_id': 58, 'iscrowd': 0, 'segmentation': []}]\n"
     ]
    }
   ],
   "source": [
    "img, anno1, h, w, id = dataset.pull_item(10)\n",
    "\n",
    "anno2 = dataset.pull_anno(10)\n",
    "print(\"--------anno1----------\")\n",
    "print(anno1)\n",
    "print(\"--------anno2----------\")\n",
    "print(anno2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7acfa348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4299954170485793, 0.20585825747724318, 1.3081439046746104, 1.0434980494148245]\n"
     ]
    }
   ],
   "source": [
    "scale = np.array([w, h, w, h])\n",
    "\n",
    "bbox = [938.25, 316.61, 1916.12, 1288.29]\n",
    "bbox[2] += bbox[0]\n",
    "bbox[3] += bbox[1]\n",
    "final = list(np.array(bbox) / scale)\n",
    "print(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98d2888c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading model!\n",
      "Testing image 1/100....\n",
      "5\n",
      "torch.Size([1, 8732, 2])\n",
      "1 label: line score: tensor(0.7946) 1325.9536 || 28.157701 || 1808.8206 || 503.22498\n",
      "Testing image 2/100....\n",
      "8\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 3/100....\n",
      "17\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 4/100....\n",
      "21\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 5/100....\n",
      "22\n",
      "torch.Size([1, 8732, 2])\n",
      "1 label: line score: tensor(0.8157) 1511.2793 || 542.6512 || 2238.4834 || 717.06506\n",
      "Testing image 6/100....\n",
      "27\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 7/100....\n",
      "34\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 8/100....\n",
      "40\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 9/100....\n",
      "45\n",
      "torch.Size([1, 8732, 2])\n",
      "1 label: line score: tensor(0.7153) 480.8888 || 361.0623 || 516.271 || 516.3693\n",
      "Testing image 10/100....\n",
      "54\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 11/100....\n",
      "58\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 12/100....\n",
      "61\n",
      "torch.Size([1, 8732, 2])\n",
      "1 label: line score: tensor(0.7396) 655.9087 || 575.2711 || 1295.0857 || 802.3461\n",
      "Testing image 13/100....\n",
      "62\n",
      "torch.Size([1, 8732, 2])\n",
      "1 label: line score: tensor(0.7104) 513.2003 || 692.1969 || 597.5925 || 807.70264\n",
      "2 label: line score: tensor(0.6730) 399.39203 || 780.1019 || 576.3245 || 834.85693\n",
      "Testing image 14/100....\n",
      "71\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 15/100....\n",
      "84\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 16/100....\n",
      "88\n",
      "torch.Size([1, 8732, 2])\n",
      "1 label: line score: tensor(0.6930) 179.11302 || 955.3258 || 517.7742 || 980.7301\n",
      "Testing image 17/100....\n",
      "89\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 18/100....\n",
      "105\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 19/100....\n",
      "116\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 20/100....\n",
      "118\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 21/100....\n",
      "129\n",
      "torch.Size([1, 8732, 2])\n",
      "1 label: line score: tensor(0.9962) 1006.2451 || 940.7287 || 1588.1506 || 1095.9376\n",
      "2 label: line score: tensor(0.9707) 1039.103 || 876.2711 || 1557.0079 || 1041.9342\n",
      "3 label: line score: tensor(0.9195) 383.20123 || 487.1766 || 932.9876 || 693.004\n",
      "4 label: line score: tensor(0.6935) 1182.4885 || 627.0877 || 1218.7162 || 734.71747\n",
      "Testing image 22/100....\n",
      "130\n",
      "torch.Size([1, 8732, 2])\n",
      "1 label: line score: tensor(0.8396) 740.17334 || 1166.9302 || 1255.9917 || 1471.8881\n",
      "Testing image 23/100....\n",
      "137\n",
      "torch.Size([1, 8732, 2])\n",
      "1 label: line score: tensor(0.8445) 522.23157 || 602.5553 || 955.18945 || 806.3094\n",
      "Testing image 24/100....\n",
      "138\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 25/100....\n",
      "140\n",
      "torch.Size([1, 8732, 2])\n",
      "1 label: line score: tensor(0.8896) 1150.111 || 306.789 || 1342.6935 || 687.37225\n",
      "2 label: line score: tensor(0.8678) 1677.336 || 642.29047 || 1941.4012 || 840.61615\n",
      "3 label: line score: tensor(0.8150) 1249.8557 || 304.4377 || 1454.9011 || 749.263\n",
      "Testing image 26/100....\n",
      "144\n",
      "torch.Size([1, 8732, 2])\n",
      "1 label: line score: tensor(0.6323) 1547.4169 || 352.99014 || 1606.1487 || 965.303\n",
      "Testing image 27/100....\n",
      "145\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 28/100....\n",
      "154\n",
      "torch.Size([1, 8732, 2])\n",
      "1 label: line score: tensor(0.7046) 1297.4894 || 503.44324 || 1333.3123 || 717.17053\n",
      "Testing image 29/100....\n",
      "156\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 30/100....\n",
      "171\n",
      "torch.Size([1, 8732, 2])\n",
      "1 label: line score: tensor(0.6545) 145.42598 || 613.2916 || 730.12616 || 958.3111\n",
      "Testing image 31/100....\n",
      "175\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 32/100....\n",
      "190\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 33/100....\n",
      "191\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 34/100....\n",
      "201\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 35/100....\n",
      "204\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 36/100....\n",
      "205\n",
      "torch.Size([1, 8732, 2])\n",
      "1 label: line score: tensor(0.7260) 1274.4846 || 856.00037 || 1487.4867 || 904.556\n",
      "Testing image 37/100....\n",
      "212\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 38/100....\n",
      "217\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 39/100....\n",
      "221\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 40/100....\n",
      "222\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 41/100....\n",
      "231\n",
      "torch.Size([1, 8732, 2])\n",
      "1 label: line score: tensor(0.7996) 1082.7816 || 340.26315 || 1632.8706 || 586.5421\n",
      "Testing image 42/100....\n",
      "235\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 43/100....\n",
      "238\n",
      "torch.Size([1, 8732, 2])\n",
      "1 label: line score: tensor(0.8135) 1547.724 || 235.13493 || 2071.0938 || 546.7688\n",
      "2 label: line score: tensor(0.6122) 1376.8109 || 1037.3671 || 2203.1301 || 1309.0742\n",
      "Testing image 44/100....\n",
      "240\n",
      "torch.Size([1, 8732, 2])\n",
      "1 label: line score: tensor(0.9473) 496.76285 || 327.85587 || 843.05493 || 473.8914\n",
      "2 label: line score: tensor(0.8345) 639.3902 || 675.33234 || 949.593 || 836.1613\n",
      "Testing image 45/100....\n",
      "241\n",
      "torch.Size([1, 8732, 2])\n",
      "1 label: line score: tensor(0.6236) 1017.2915 || 498.5017 || 1236.094 || 638.20844\n",
      "Testing image 46/100....\n",
      "244\n",
      "torch.Size([1, 8732, 2])\n",
      "1 label: line score: tensor(0.6528) 547.8218 || 329.5078 || 996.65656 || 406.82294\n",
      "Testing image 47/100....\n",
      "248\n",
      "torch.Size([1, 8732, 2])\n",
      "1 label: line score: tensor(0.8031) 1529.6814 || 367.64813 || 1771.1553 || 489.4002\n",
      "2 label: line score: tensor(0.7718) 1547.269 || 411.06735 || 1771.2101 || 539.4522\n",
      "Testing image 48/100....\n",
      "259\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 49/100....\n",
      "273\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 50/100....\n",
      "275\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 51/100....\n",
      "278\n",
      "torch.Size([1, 8732, 2])\n",
      "1 label: line score: tensor(0.8002) 453.424 || 312.7439 || 855.55005 || 521.7368\n",
      "2 label: line score: tensor(0.6663) 465.5821 || 407.9176 || 897.17883 || 612.2921\n",
      "Testing image 52/100....\n",
      "280\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 53/100....\n",
      "282\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 54/100....\n",
      "283\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 55/100....\n",
      "285\n",
      "torch.Size([1, 8732, 2])\n",
      "1 label: line score: tensor(0.9647) 1277.6332 || 551.8657 || 1495.9307 || 1119.8071\n",
      "Testing image 56/100....\n",
      "286\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 57/100....\n",
      "291\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 58/100....\n",
      "299\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 59/100....\n",
      "312\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 60/100....\n",
      "314\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 61/100....\n",
      "316\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 62/100....\n",
      "319\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 63/100....\n",
      "320\n",
      "torch.Size([1, 8732, 2])\n",
      "1 label: line score: tensor(0.7276) 639.8886 || 1583.942 || 798.51984 || 1636.1156\n",
      "2 label: line score: tensor(0.6308) 641.9042 || 1626.1709 || 786.87054 || 1681.9402\n",
      "Testing image 64/100....\n",
      "325\n",
      "torch.Size([1, 8732, 2])\n",
      "1 label: line score: tensor(0.8840) 122.60391 || 638.0308 || 156.612 || 822.26624\n",
      "2 label: line score: tensor(0.7032) 290.86456 || 617.54596 || 342.49707 || 834.26654\n",
      "Testing image 65/100....\n",
      "332\n",
      "torch.Size([1, 8732, 2])\n",
      "1 label: line score: tensor(0.8748) 270.16418 || 775.29944 || 619.2821 || 961.2756\n",
      "2 label: line score: tensor(0.8196) 423.50912 || 506.65787 || 813.8118 || 749.0578\n",
      "3 label: line score: tensor(0.6866) 303.95343 || 651.2276 || 667.15826 || 853.6378\n",
      "4 label: line score: tensor(0.6791) 474.8989 || 406.7031 || 804.26373 || 645.0425\n",
      "Testing image 66/100....\n",
      "337\n",
      "torch.Size([1, 8732, 2])\n",
      "1 label: line score: tensor(0.6286) 1102.7412 || 896.60455 || 1237.3962 || 1007.7244\n",
      "2 label: line score: tensor(0.6243) 927.67847 || 597.06836 || 1060.7957 || 820.6065\n",
      "Testing image 67/100....\n",
      "345\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 68/100....\n",
      "347\n",
      "torch.Size([1, 8732, 2])\n",
      "1 label: line score: tensor(0.9128) 78.87051 || 179.47339 || 348.6954 || 592.7549\n",
      "Testing image 69/100....\n",
      "349\n",
      "torch.Size([1, 8732, 2])\n",
      "1 label: line score: tensor(0.8123) 870.69946 || 306.9221 || 1319.0095 || 481.10828\n",
      "2 label: line score: tensor(0.6251) 882.1351 || 225.47517 || 1313.0128 || 370.02258\n",
      "Testing image 70/100....\n",
      "354\n",
      "torch.Size([1, 8732, 2])\n",
      "1 label: line score: tensor(0.9562) 93.4353 || 1351.92 || 1368.7606 || 1381.7335\n",
      "2 label: line score: tensor(0.9444) 63.472187 || 1244.0264 || 1392.6506 || 1272.2827\n",
      "3 label: line score: tensor(0.9269) 9.07048 || 1130.2312 || 1455.346 || 1156.7188\n",
      "4 label: line score: tensor(0.9072) 36.335 || 1440.6321 || 1418.7727 || 1474.4907\n",
      "5 label: line score: tensor(0.8476) -19.263163 || 1015.9498 || 1502.4642 || 1040.1449\n",
      "6 label: line score: tensor(0.8072) -19.691317 || 893.3455 || 1488.5723 || 919.27423\n",
      "7 label: line score: tensor(0.7281) 7.231908 || 1571.077 || 1479.7682 || 1602.2009\n",
      "8 label: line score: tensor(0.6571) 70.88024 || 786.88806 || 1376.2117 || 814.0264\n",
      "Testing image 71/100....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 72/100....\n",
      "369\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 73/100....\n",
      "373\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 74/100....\n",
      "379\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 75/100....\n",
      "380\n",
      "torch.Size([1, 8732, 2])\n",
      "1 label: line score: tensor(0.7053) 1051.1968 || 1655.5355 || 1185.8236 || 2027.3173\n",
      "2 label: line score: tensor(0.6707) 625.5484 || 392.54688 || 805.38824 || 750.6601\n",
      "3 label: line score: tensor(0.6430) 743.68976 || 234.83446 || 960.8168 || 602.82074\n",
      "Testing image 76/100....\n",
      "385\n",
      "torch.Size([1, 8732, 2])\n",
      "1 label: line score: tensor(0.6191) 269.45172 || 404.26834 || 541.1997 || 598.7088\n",
      "Testing image 77/100....\n",
      "388\n",
      "torch.Size([1, 8732, 2])\n",
      "1 label: line score: tensor(0.8777) 1032.3704 || -41.434414 || 1359.1345 || 326.73788\n",
      "2 label: line score: tensor(0.7688) 465.9035 || 1622.0425 || 972.02423 || 1716.5654\n",
      "3 label: line score: tensor(0.6499) 218.3825 || 1179.7089 || 1339.9445 || 1214.6613\n",
      "4 label: line score: tensor(0.6114) 279.01608 || 1085.6093 || 1352.2797 || 1116.7754\n",
      "Testing image 78/100....\n",
      "399\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 79/100....\n",
      "401\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 80/100....\n",
      "407\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 81/100....\n",
      "411\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 82/100....\n",
      "413\n",
      "torch.Size([1, 8732, 2])\n",
      "1 label: line score: tensor(0.6510) 327.97055 || 1842.6328 || 455.8175 || 1932.1449\n",
      "Testing image 83/100....\n",
      "414\n",
      "torch.Size([1, 8732, 2])\n",
      "1 label: line score: tensor(0.8412) 399.8241 || 590.3604 || 841.69183 || 738.15015\n",
      "2 label: line score: tensor(0.6574) 411.61795 || 700.7922 || 886.20056 || 822.69635\n",
      "Testing image 84/100....\n",
      "415\n",
      "torch.Size([1, 8732, 2])\n",
      "1 label: line score: tensor(0.9265) 429.47757 || 1332.9336 || 635.2436 || 1644.1825\n",
      "2 label: line score: tensor(0.7202) 1163.649 || 1617.247 || 1373.346 || 1932.0323\n",
      "3 label: line score: tensor(0.7021) 490.9987 || 1177.5935 || 692.3181 || 1482.9293\n",
      "4 label: line score: tensor(0.6248) 864.80963 || 473.10934 || 1113.4504 || 815.28094\n",
      "Testing image 85/100....\n",
      "420\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 86/100....\n",
      "424\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 87/100....\n",
      "425\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 88/100....\n",
      "434\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 89/100....\n",
      "441\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 90/100....\n",
      "446\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 91/100....\n",
      "449\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 92/100....\n",
      "452\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 93/100....\n",
      "457\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 94/100....\n",
      "458\n",
      "torch.Size([1, 8732, 2])\n",
      "1 label: line score: tensor(0.9941) 639.6439 || 1510.6495 || 871.0773 || 1947.6804\n",
      "Testing image 95/100....\n",
      "459\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 96/100....\n",
      "464\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 97/100....\n",
      "485\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 98/100....\n",
      "488\n",
      "torch.Size([1, 8732, 2])\n",
      "1 label: line score: tensor(0.7823) 233.03596 || 1505.1517 || 383.48486 || 1583.5327\n",
      "Testing image 99/100....\n",
      "489\n",
      "torch.Size([1, 8732, 2])\n",
      "Testing image 100/100....\n",
      "493\n",
      "torch.Size([1, 8732, 2])\n",
      "1 label: line score: tensor(0.7708) 656.1863 || 29.088493 || 1154.0815 || 148.16196\n",
      "2 label: line score: tensor(0.7471) 683.3947 || 139.9605 || 1224.6072 || 237.56943\n",
      "3 label: line score: tensor(0.6776) 651.2114 || 355.39136 || 1311.2386 || 466.9546\n",
      "4 label: line score: tensor(0.6437) 667.60974 || 247.03906 || 1279.7532 || 372.03574\n",
      "5 label: line score: tensor(0.6011) 765.3947 || 818.7813 || 1409.3196 || 882.05853\n"
     ]
    }
   ],
   "source": [
    "net = build_ssd(phase='test', size=300, num_classes=2)\n",
    "net.load_state_dict(torch.load('./weights/linedataset_vol1_1a.pth'))\n",
    "net.eval()\n",
    "print(\"Finished loading model!\")\n",
    "\n",
    "test_net(save_folder, net, True, dataset, BaseTransform(net.size, (104, 117, 123)), 0.6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5a9cb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aaa7d6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247dadd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2622bde3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssd_train",
   "language": "python",
   "name": "ssd_train"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
