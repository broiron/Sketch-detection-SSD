{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac92923b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/broiron/.local/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from data import *\n",
    "from PIL import Image\n",
    "from utils.augmentations import SSDAugmentation\n",
    "\n",
    "import torch.utils.data as data\n",
    "from ssd import build_ssd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b96426b",
   "metadata": {},
   "source": [
    "### check cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af6d365c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "    \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c24a8b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = os.path.join(os.getcwd(), 'test')\n",
    "if not os.path.exists(save_folder):\n",
    "    os.mkdir(save_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d430bea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_net(save_folder, net, cuda, testset, transform, thresh):\n",
    "    # dump predictions and assoc. ground truth to text file for now\n",
    "    filename = os.path.join(save_folder, 'test1.txt')\n",
    "    num_images = len(testset)\n",
    "    for i in range(num_images):\n",
    "        print('Testing image {:d}/{:d}....'.format(i+1, num_images))\n",
    "        img, annotation, _, _, img_id = testset.pull_item(i)\n",
    "        # img, annotation, h, w = testset.pull_item(i)\n",
    "        print(img_id)\n",
    "\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(device)\n",
    "        \n",
    "        x = img.unsqueeze(0)\n",
    "        x = x.type(torch.FloatTensor)\n",
    "        x = x.to(device)\n",
    "        x = Variable(x)\n",
    "\n",
    "        with open(filename, mode='a') as f:\n",
    "            f.write('\\nGROUND TRUTH FOR: '+str(img_id)+'\\n')\n",
    "            for box in annotation:\n",
    "                f.write('label: '+' || '.join(str(b) for b in box)+'\\n')\n",
    "\n",
    "        net = net.to(device)\n",
    "        y = net(x)      # forward pass\n",
    "        detections = y.data\n",
    "        # scale each detection back up to the image\n",
    "        scale = torch.Tensor([img.shape[1], img.shape[0],\n",
    "                             img.shape[1], img.shape[0]])\n",
    "        pred_num = 0\n",
    "        for i in range(detections.size(1)):\n",
    "            j = 0\n",
    "            while detections[0, i, j, 0] >= args.visual_threshold:\n",
    "                if pred_num == 0:\n",
    "                    with open(filename, mode='a') as f:\n",
    "                        f.write('PREDICTIONS: '+'\\n')\n",
    "                score = detections[0, i, j, 0]\n",
    "                label_name = CUSTOM_CLASSES[i-1]\n",
    "                pt = (detections[0, i, j, 1:]*scale).cpu().numpy()\n",
    "                coords = (pt[0], pt[1], pt[2], pt[3])\n",
    "                pred_num += 1\n",
    "                with open(filename, mode='a') as f:\n",
    "                    f.write(str(pred_num)+' label: '+label_name+' score: ' +\n",
    "                            str(score) + ' '+' || '.join(str(c) for c in coords) + '\\n')\n",
    "                print(str(pred_num)+' label: '+label_name+' score: ' +\n",
    "                            str(score) + ' '+' || '.join(str(c) for c in coords))\n",
    "                j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50ac993c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading model!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Testing image 1/100....\n",
      "5\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/broiron/broiron/model_train/ssd-pytorch-custom/utils/augmentations.py:238: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  mode = random.choice(self.sample_options)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "forward() missing 1 required positional argument: 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_38682/3009062948.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                         transform=SSDAugmentation(300, MEANS), image_set='test')\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtest_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m104\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m117\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m123\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_38682/1030988666.py\u001b[0m in \u001b[0;36mtest_net\u001b[0;34m(save_folder, net, cuda, testset, transform, thresh)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m      \u001b[0;31m# forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mdetections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# scale each detection back up to the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ssd_train/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'x'"
     ]
    }
   ],
   "source": [
    "net = build_ssd(phase='test', size=300, num_classes=2)\n",
    "net.load_state_dict(torch.load('./weights/linedataset_vol1_1a.pth'))\n",
    "net.eval()\n",
    "print(\"Finished loading model!\")\n",
    "\n",
    "testset = COCODetection(root='/home/broiron/broiron/line_dataset_vol1_coco/', \n",
    "                        transform=SSDAugmentation(300, MEANS), image_set='test')\n",
    "\n",
    "test_net(save_folder, net, True, testset, BaseTransform(net.size, (104, 117, 123)), 0.6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed176ad4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssd_train",
   "language": "python",
   "name": "ssd_train"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
